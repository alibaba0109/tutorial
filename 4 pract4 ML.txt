Practical No 4
from google.colab import files
uploaded=files.upload()
import pandas as pd
import seaborn as sn
import nltk
df=pd.read_csv('SMSSpamCollection', sep='\t', names=['label','text'])
print(df)
print(df.shape)
nltk.download('stopwords')
nltk.download('punkt')
sent = 'How are you friends?'
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
swords = stopwords.words('english')
from nltk.stem import PorterStemmer
ps = PorterStemmer()
Output:


#A]Data pre-processing
def clean_text(sent):
  tokens = word_tokenize(sent)
  clean = [word for word in  tokens
           if word.isdigit()or word.isalpha()]

  clean =[ps.stem(word) for word in clean 
          if word not in swords]
  return(clean)
clean_text(sent)
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(analyzer=clean_text)
x=df['text']
y=df['label']
print(x)
print(y)
x_new=tfidf.fit_transform(x)
print(x.shape)
print(x_new.shape)
tfidf.get_feature_names()
y.value_counts()

Output:
0       Go until jurong point, crazy.. Available only ...
1                           Ok lar... Joking wif u oni...
2       Free entry in 2 a wkly comp to win FA Cup fina...
3       U dun say so early hor... U c already then say...
4       Nah I don't think he goes to usf, he lives aro...
                              ...                        
5567    This is the 2nd time we have tried 2 contact u...
5568                 Will ü b going to esplanade fr home?
5569    Pity, * was in mood for that. So...any other s...
5570    The guy did some bitching but I acted like i'd...
5571                           Rofl. Its true to its name
Name: text, Length: 5572, dtype: object
0        ham
1        ham
2       spam
3        ham
4        ham
        ... 
5567    spam
5568     ham
5569     ham
5570     ham
5571     ham
Name: label, Length: 5572, dtype: object
(5572,)
(5572, 6513)
/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.
  warnings.warn(msg, category=FutureWarning)
ham     4825
spam     747
Name: label, dtype: int64

#b) Train-Test-Split(Cross Validation)
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test=train_test_split(x_new,y, random_state=0,test_size=.25)
x_train.shape
x_test.shape
Output:


#1 Naive Bayes Algorithm
from sklearn.naive_bayes import GaussianNB
nb=GaussianNB()
nb.fit(x_train.toarray(),y_train)
y_pred=nb.predict(x_test.toarray())
y_test.value_counts()
from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)
from sklearn.metrics import accuracy_score, classification_report
print(classification_report(y_test,y_pred))
accuracy_score(y_test,y_pred)
Output:


#2 Random Forest Algorithm
from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(random_state=0)
rf.fit(x_train,y_train)
y_pred=rf.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)
print(classification_report(y_test,y_pred))
accuracy_score(y_test,y_pred)
Output:


#3 Logistic Regression
from sklearn.linear_model import LogisticRegression
log=LogisticRegression()
log.fit(x_train,y_train)
y_pred=log.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)
print(classification_report(y_test,y_pred))
accuracy_score(y_test,y_pred)
Output:


#e) Hyper Parameter Tuning
from sklearn.model_selection import GridSearchCV
params={
    'criterion':['gini','entropy'],
    'max_features':['sqrt','log2'],
    'random_state':[0,1,2,3,4],
    'class_weight':['balanced','balanced_subsample']
}
grid=GridSearchCV(rf,param_grid=params,cv=5, scoring='accuracy')
grid.fit(x_train,y_train)
rf=grid.best_estimator_
y_pred=rf.predict(x_test)
accuracy_score(y_test, y_pred)
Output:
0.9791816223977028
